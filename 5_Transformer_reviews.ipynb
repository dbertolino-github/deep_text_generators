{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import dependencies \n",
    "Importing needed dependencies.\n",
    "In this first step we also define all global variables that will help managing redundancy:\n",
    "- __*PREPROCESS*__: preprocessing type (Continous or splitted on dots)\n",
    "- __*EPOCHS*__: number of epochs in which the training is divided.\n",
    "- __*SENTENCES_MAX_LENGTH*__: Maximum length of the variable dimension phrases..\n",
    "- __*BATCH_SIZE*__: number of samples after which update the weights.\n",
    "- __*EMBEDDING_DIM*__: number of neurons in the Embeddings layer.\n",
    "- __*HIDDEN_DIM*__: number of LSTM units in the network.\n",
    "- __*ENCODERS*__: number of encoders in the architecture.\n",
    "- __*DECODERS*__: number of decoders in the architecture.\n",
    "- __*DROPOUT_RATE*__: Dropout value.\n",
    "- __*HEADS_ATTENTION*__: number of words considered by the self-attention mechanism.\n",
    "- __*ACTIVATION_FUNCTION*__: Used by the feedforward layers in the transformer model.\n",
    "- __*NUM_REVIEWS*__: Number of reviews to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gensim\n",
    "from copy import deepcopy\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.utils import shuffle\n",
    "from keras_transformer import get_model, decode\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.models import load_model\n",
    "\n",
    "EPOCHS = 100\n",
    "SENTENCES_MAX_LENGTH = 20\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 1024\n",
    "ENCODERS = 1\n",
    "DECODERS = 1\n",
    "DROPOUT_RATE = 0.1\n",
    "HEADS_ATTENTION = 8\n",
    "ACTIVATION_FUNCTION = 'relu'\n",
    "NUM_REVIEWS = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Booking reviews data\n",
    "The chosen data are extracted from a dataset of 515K reviews available on Kaggle.\n",
    "The entire dataset is available at this link <a href=\"https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe\">link</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 reviews cleaned and imported.\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    '''\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"ain't\", \"am not\")\n",
    "    text = text.replace(\"aren't\", \"are not\")\n",
    "    text = text.replace(\"can't\", \"cannot\")\n",
    "    text = text.replace(\"can't've\", \"cannot have\")\n",
    "    text = text.replace(\"'cause\", \"because\")\n",
    "    text = text.replace(\"could've\", \"could have\")\n",
    "    text = text.replace(\"couldn't\", \"could not\")\n",
    "    text = text.replace(\"couldn't've\", \"could not have\")\n",
    "    text = text.replace(\"should've\", \"should have\")\n",
    "    text = text.replace(\"should't\", \"should not\")\n",
    "    text = text.replace(\"should't've\", \"should not have\")\n",
    "    text = text.replace(\"would've\", \"would have\")\n",
    "    text = text.replace(\"would't\", \"would not\")\n",
    "    text = text.replace(\"would't've\", \"would not have\")\n",
    "    text = text.replace(\"didn't\", \"did not\")\n",
    "    text = text.replace(\"doesn't\", \"does not\")\n",
    "    text = text.replace(\"don't\", \"do not\")\n",
    "    text = text.replace(\"hadn't\", \"had not\")\n",
    "    text = text.replace(\"hadn't've\", \"had not have\")\n",
    "    text = text.replace(\"hasn't\", \"has not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"he'd\", \"he would\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"he'd've\", \"he would have\")\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    text = text.replace(\"'t\", \"\")\n",
    "    text = text.replace(\"'ve\", \"\")\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\"!\", \" ! \")\n",
    "    text = text.replace(\"?\", \" ? \")\n",
    "    text = text.replace(\";\", \" ; \")\n",
    "    text = text.replace(\":\", \" : \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = text.replace(\"´\", \"\")\n",
    "    text = text.replace(\"‘\", \"\")\n",
    "    text = text.replace(\"’\", \"\")\n",
    "    text = text.replace(\"“\", \"\")\n",
    "    text = text.replace(\"”\", \"\")\n",
    "    text = text.replace(\"\\'\", \"\")\n",
    "    text = text.replace(\"\\\"\", \"\")\n",
    "    text = text.replace(\"-\", \"\")\n",
    "    text = text.replace(\"–\", \"\")\n",
    "    text = text.replace(\"—\", \"\")\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\",\"\")\n",
    "    text = text.replace(\"{\",\"\")\n",
    "    text = text.replace(\"}\", \"\")\n",
    "    text = text.replace(\"/\", \"\")\n",
    "    text = text.replace(\"|\", \"\")\n",
    "    text = text.replace(\"(\", \"\")\n",
    "    text = text.replace(\")\", \"\")\n",
    "    text = text.replace(\"$\", \"\")\n",
    "    text = text.replace(\"+\", \"\")\n",
    "    text = text.replace(\"*\", \"\")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    return text\n",
    "\n",
    "try:\n",
    "    \n",
    "    types = {\n",
    "    'reviews_text' : str,\n",
    "    }\n",
    "\n",
    "    # Importing dataset\n",
    "    reviews_df = pd.read_csv('input_data/text_reviews.csv', dtype=types)\n",
    "    reviews = reviews_df['reviews_text'].values\n",
    "    reviewsCleaned = []\n",
    "\n",
    "    for r in reviews:\n",
    "        cleaned = clean(r)\n",
    "        splitted = cleaned.split(' ')\n",
    "        l = len(splitted)\n",
    "        if l > 3 and l <= 30:\n",
    "            reviewsCleaned.append(cleaned)\n",
    "            \n",
    "        reviewsCleaned = reviewsCleaned[:NUM_REVIEWS]\n",
    "    \n",
    "    print('{} reviews cleaned and imported.'.format(NUM_REVIEWS))\n",
    "\n",
    "except IOError:\n",
    "    sys.exit('Cannot find data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to investigate on fables max length and average length to better decided preprocess hyperparamateres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 4000\n",
      "Max length: 30\n",
      "Avg length: 13.09525\n"
     ]
    }
   ],
   "source": [
    "sumLen = 0\n",
    "maxLen = 0\n",
    "\n",
    "for r in reviewsCleaned:\n",
    "    splitted = r.split(' ')\n",
    "    l = len(splitted)\n",
    "    sumLen += l\n",
    "    if l > maxLen : maxLen = l\n",
    "\n",
    "avgLen = sumLen/len(reviewsCleaned)\n",
    "print('Number of reviews: {}'.format(len(reviewsCleaned)))\n",
    "print('Max length: {}'.format(maxLen))\n",
    "print('Avg length: {}'.format(avgLen))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Vocabulary\n",
    "The vocabulary is saved as: \n",
    "- a __numpy array__ to map each encoding to the right word\n",
    "- a __dictionary__ to map each word to its encoding number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<START>', '<END>']\n",
      "Vocabulary Size: 3719\n"
     ]
    }
   ],
   "source": [
    "idx2word = []\n",
    "word2idx = {'<PAD>' : 0, '<START>' : 1 , '<END>': 2}\n",
    "\n",
    "for r in reviewsCleaned:\n",
    "    words = r.split(' ')\n",
    "\n",
    "    b=True\n",
    "    while b:\n",
    "        if('' in words): \n",
    "            words.remove('')\n",
    "        else: b = False\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "for word in idx2word:\n",
    "    word2idx[word] = len(word2idx)\n",
    "\n",
    "idx2word = list(word2idx.keys())\n",
    "print(idx2word[:3])\n",
    "vocabLength = len(idx2word)\n",
    "print('Vocabulary Size: {}'.format(vocabLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess text\n",
    "\n",
    "The Transoformer model has an Encoder-Decoder architecture so we can train the model to generate variable dimension sequences, meaning that it will be the model itself to decide how many words have to be generated for a determined input sequence.\n",
    "However in order to achieve this result the text has to preprocessed in a way that let the model understand where a sequence starts and where it ends.\n",
    "In fact in the previous code cell we had these three tokens to the vocabulary:\n",
    "\n",
    "```python\n",
    "word2idx = {'<PAD>' : 0, '<START>' : 1 , '<END>': 2}\n",
    "```\n",
    "I will compare two types of preprocessing, the first identified as __continous__ divides the text into sequences of words, respecting a maximum length decided a priori.Each sequence will generate as many samples as its number of words.\n",
    "\n",
    "For example, say SEQUENCES_LENGTH is 4 and our text is \"Hello my name is Dario and I love to code\". \n",
    "- Sequences: \"Hello my name is \", \"Dario and I love\", \"to code\"\n",
    "\n",
    "Then with the first sequence:\n",
    "- __EncoderInput__: \"START Hello END\" <br/>\n",
    "  __DecoderInput__: \"START my name is END\" <br/>\n",
    "  __Target__: \"my name is END\" <br/>\n",
    "  \n",
    "  \n",
    "- __EncoderInput__: \"START Hello my END\" <br/>\n",
    "  __DecoderInput__: \"START name is END\"<br/>\n",
    "  __Target__: \"name is END\"<br/>\n",
    "  \n",
    "  \n",
    "- __EncoderInput__:  \"START Hello my name END\"<br/>\n",
    "  __DecoderInput__: \"START is END\"<br/>\n",
    "  __Target__: \"is END\"<br/>\n",
    "  \n",
    "  \n",
    "- __EncoderInput__: \"START Hello my name is END\" <br/>\n",
    "  __DecoderInput__: \"START END\"<br/>\n",
    "  __Target__: \"END\"<br/>\n",
    "\n",
    "\n",
    "\n",
    "The second one, indetified as __dots__, instead of divide continous sequences of the maximum length simply split the fables by dots and then apply the same inputs/target generation to the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 41347\n",
      "Creating dataset to feed Model . . . \n",
      "Dataset printed on CSV.\n"
     ]
    }
   ],
   "source": [
    "def createInputTarget(words) :\n",
    "    \n",
    "    encoder = []\n",
    "    decoder = []\n",
    "    output = []\n",
    "    \n",
    "    for i in range(1, len(words)):\n",
    "        encode_tokens, decode_tokens = words[:i], words[i:]\n",
    "        encode_tokens = ' '.join(['<START>'] + encode_tokens + ['<END>'])\n",
    "        output_tokens = ' '.join(decode_tokens + ['<END>'])\n",
    "        decode_tokens = ' '.join(['<START>'] + decode_tokens + ['<END>'])\n",
    "        encoder.append(encode_tokens)\n",
    "        decoder.append(decode_tokens)\n",
    "        output.append(output_tokens)\n",
    "        \n",
    "    return encoder, decoder, output\n",
    "\n",
    "def getWordTokens(sentence):\n",
    "    #clean tokens\n",
    "    words = sentence.split(' ')\n",
    "    words.append('.')\n",
    "    b=True\n",
    "    while b:\n",
    "        if('' in words): \n",
    "            words.remove('')\n",
    "        else: b = False\n",
    "    \n",
    "    return words\n",
    "\n",
    "def checkMaxLength(words):\n",
    "    \n",
    "    seq = []\n",
    "    \n",
    "    if len(words) > SENTENCES_MAX_LENGTH :\n",
    "        seq.append(words[:SENTENCES_MAX_LENGTH])\n",
    "        seq.append(words[SENTENCES_MAX_LENGTH:])\n",
    "        while len(seq[-1]) > SENTENCES_MAX_LENGTH:\n",
    "            tmp = deepcopy(seq[-1])\n",
    "            del seq[-1]\n",
    "            seq.append(tmp[:SENTENCES_MAX_LENGTH])\n",
    "            seq.append(tmp[SENTENCES_MAX_LENGTH:])\n",
    "    else : \n",
    "        seq.append(words)\n",
    "\n",
    "    return seq\n",
    "\n",
    "# EXTRACT ENCODER & DECODER INPUT SENTENCES\n",
    "inputSentences = []\n",
    "targetSentences = []\n",
    "outputSentences = []\n",
    "\n",
    "\n",
    "for r in reviewsCleaned:\n",
    "    words = r.split(' ')\n",
    "\n",
    "    b=True\n",
    "    while b:\n",
    "        if('' in words): \n",
    "            words.remove('')\n",
    "        else: b = False\n",
    "\n",
    "    sentences = [words[i:i+SENTENCES_MAX_LENGTH] for i in range(0, len(words), SENTENCES_MAX_LENGTH)]\n",
    "    for s in sentences:\n",
    "        for i in range(1, len(s)):\n",
    "            encode_tokens, decode_tokens = s[:i], s[i:]\n",
    "            encode_tokens = ' '.join(['<START>'] + encode_tokens + ['<END>'])\n",
    "            output_tokens = ' '.join(decode_tokens + ['<END>'])\n",
    "            decode_tokens = ' '.join(['<START>'] + decode_tokens + ['<END>'])\n",
    "            inputSentences.append(encode_tokens)\n",
    "            targetSentences.append(decode_tokens)\n",
    "            outputSentences.append(output_tokens)\n",
    "\n",
    "numSamples = len(inputSentences)\n",
    "print('Num samples: {}'.format(numSamples))\n",
    "\n",
    "print(\"Creating dataset to feed Model . . . \")\n",
    "dirname = os.path.abspath('')\n",
    "filePath = os.path.join(dirname, os.path.join(dirname, 'preprocessed/dataset_reviews_{}_{}_{}_{}_{}.csv'.format(\n",
    "EPOCHS, \n",
    "SENTENCES_MAX_LENGTH, \n",
    "BATCH_SIZE, \n",
    "EMBEDDING_DIM,\n",
    "HIDDEN_DIM)))\n",
    "\n",
    "if os.path.exists(filePath):\n",
    "    os.remove(filePath) \n",
    "\n",
    "d= {'input_encoder' : inputSentences, 'input_decoder' :targetSentences, 'output_decoder':outputSentences }\n",
    "df = pd.DataFrame(data=d) \n",
    "#df = shuffle(df)\n",
    "df.to_csv(filePath, index=False)\n",
    "\n",
    "print(\"Dataset printed on CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what is the purpose of the padding token?\n",
    "```python\n",
    "'<PAD>' : 0\n",
    "```\n",
    "\n",
    "In order to be able to feed the model we need to create inputs of the same length.\n",
    "This is way I defined a function to generate final data with paddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(word_2_idx, num_samples, max_length, vocab_length, batch_size=BATCH_SIZE):\n",
    "    '''\n",
    "    '''\n",
    "    dirname = os.path.abspath('')\n",
    "    filePath = os.path.join(dirname, 'preprocessed/dataset_reviews_{}_{}_{}_{}_{}.csv'.format(\n",
    "    EPOCHS, \n",
    "    SENTENCES_MAX_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM))\n",
    "    df = pd.read_csv(filePath)\n",
    "    \n",
    "    encoderInputData = np.zeros((numSamples, max_length + 2), dtype='int')\n",
    "    decoderInputData = np.zeros((numSamples, max_length + 2), dtype='int')\n",
    "    decoderTargetData = np.zeros((numSamples, max_length + 2, 1),dtype='int')\n",
    "    \n",
    "    for i in range(0, numSamples):\n",
    "        if(i%10000 == 0):print('Generating feeding data... {}/{}'.format(i,numSamples))    \n",
    "        encoderTokens = df.iloc[[i]]['input_encoder'].values[0].split(' ')\n",
    "        decoderTokens = df.iloc[[i]]['input_decoder'].values[0].split(' ')\n",
    "        outputTokens = df.iloc[[i]]['output_decoder'].values[0].split(' ')\n",
    "\n",
    "        for t, word in enumerate(encoderTokens):\n",
    "            encoderInputData[i, t] = word_2_idx[word]\n",
    "        for t, word in enumerate(decoderTokens):\n",
    "            decoderInputData[i, t] = word_2_idx[word]\n",
    "        for t, word in enumerate(outputTokens):\n",
    "            # decoderTargetData is ahead of decoderInputData by one timestep\n",
    "            decoderTargetData[i, t, 0] = word_2_idx[word]\n",
    "\n",
    "    \n",
    "    return encoderInputData, decoderInputData, decoderTargetData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract embeddings matrix\n",
    "Loading pre-trained embeddings is a good practice to use them and in this case I calculated them with Google's Word2Vec model on the famous text8 dataset.\n",
    "- *More details on __train_embeddings.ipyn__ notebook* (To be executed if the .bin file do not exists)\n",
    "\n",
    "The embeddings are simply 128 (or whatever is the dimensionality during training) weigths from a single neuron in the input layer to the 128 neurons in the hidden layer trained to understand which words compared in the same context for a given text.\n",
    "\n",
    "So we simply extract these weights for every single word in our vocabulary and build a matrix with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 words without pre-trained embedding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Recreating embeddings index based on Tokenizer vocabulary\n",
    "word2vecModel = gensim.models.Word2Vec.load('embeddings/reviews_word2vec_skipgram_128.bin')\n",
    "word2vec_vocabulary = word2vecModel.wv.vocab\n",
    "embeddingIndex = dict()\n",
    "counter = 0\n",
    "for i, word in enumerate(idx2word):\n",
    "    if word in word2vec_vocabulary :\n",
    "        embeddingIndex[word] = word2vecModel[word]\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "print(\"{} words without pre-trained embedding!\".format(counter))\n",
    "    \n",
    "# Prepare embeddings matrix\n",
    "embeddingMatrix = np.random.random((len(word2idx), EMBEDDING_DIM))\n",
    "for i, word in enumerate(idx2word):\n",
    "    embeddingVector = embeddingIndex.get(word)\n",
    "    if embeddingVector is not None:\n",
    "        embeddingMatrix[i] = embeddingVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Or it is possible to use random weights_\n",
    "Do not execute this cell to use pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMatrix = np.random.random((len(word2idx), EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the model\n",
    "To build the transformer model I use and external library available on <a href=\"https://github.com/kpot/keras-transformer\">this GitHub repository</a>.\n",
    "The the model is trained and its weight are saved in a .h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dbertolino/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Token-Embedding (EmbeddingRet)  [(None, None, 128),  476032      Encoder-Input[0][0]              \n",
      "                                                                 Decoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Embedding (TrigPosEmbed (None, None, 128)    0           Token-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    66048       Encoder-Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Encoder-Embedding[0][0]          \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Embedding (TrigPosEmbed (None, None, 128)    0           Token-Embedding[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    256         Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 128)    66048       Decoder-Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, None, 128)    263296      Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Decoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, None, 128)    0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Decoder-Embedding[0][0]          \n",
      "                                                                 Decoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, None, 128)    0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 128)    256         Decoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, None, 128)    256         Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 128)    66048       Decoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 128)    0           Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 128)    0           Decoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 128)    256         Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward (FeedForw (None, None, 128)    263296      Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Dropout ( (None, None, 128)    0           Decoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Add (Add) (None, None, 128)    0           Decoder-1-MultiHeadQueryAttention\n",
      "                                                                 Decoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Norm (Lay (None, None, 128)    256         Decoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Output (EmbeddingSim)           (None, None, 3719)   3719        Decoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Token-Embedding[1][1]            \n",
      "==================================================================================================\n",
      "Total params: 1,205,767\n",
      "Trainable params: 729,735\n",
      "Non-trainable params: 476,032\n",
      "__________________________________________________________________________________________________\n",
      "Generating feeding data... 0/41347\n",
      "Generating feeding data... 10000/41347\n",
      "Generating feeding data... 20000/41347\n",
      "Generating feeding data... 30000/41347\n",
      "Generating feeding data... 40000/41347\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/100\n",
      "41347/41347 [==============================] - 56s 1ms/step - loss: 5.5162\n",
      "Epoch 2/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 4.1729\n",
      "Epoch 3/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 3.5740\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41347/41347 [==============================] - 54s 1ms/step - loss: 3.2255\n",
      "Epoch 5/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.9659\n",
      "Epoch 6/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.7574\n",
      "Epoch 7/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.5949\n",
      "Epoch 8/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.4639\n",
      "Epoch 9/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.3559\n",
      "Epoch 10/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.2680\n",
      "Epoch 11/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.1894\n",
      "Epoch 12/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.1253\n",
      "Epoch 13/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.0699\n",
      "Epoch 14/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 2.0182\n",
      "Epoch 15/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.9761\n",
      "Epoch 16/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.9368\n",
      "Epoch 17/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.9030\n",
      "Epoch 18/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.8686\n",
      "Epoch 19/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.8394\n",
      "Epoch 20/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.8129\n",
      "Epoch 21/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.7898\n",
      "Epoch 22/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.7631\n",
      "Epoch 23/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.7450\n",
      "Epoch 24/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.7201\n",
      "Epoch 25/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.7023\n",
      "Epoch 26/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.6885\n",
      "Epoch 27/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.6715\n",
      "Epoch 28/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.6535\n",
      "Epoch 29/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.6392\n",
      "Epoch 30/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.6238\n",
      "Epoch 31/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.6129\n",
      "Epoch 32/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5998\n",
      "Epoch 33/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5873\n",
      "Epoch 34/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5745\n",
      "Epoch 35/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5624\n",
      "Epoch 36/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5558\n",
      "Epoch 37/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5421\n",
      "Epoch 38/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5342\n",
      "Epoch 39/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5249\n",
      "Epoch 40/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5171\n",
      "Epoch 41/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.5066\n",
      "Epoch 42/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4993\n",
      "Epoch 43/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4919\n",
      "Epoch 44/100\n",
      "41347/41347 [==============================] - 53s 1ms/step - loss: 1.4839\n",
      "Epoch 45/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4759\n",
      "Epoch 46/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4671\n",
      "Epoch 47/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4599\n",
      "Epoch 48/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4509\n",
      "Epoch 49/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4485\n",
      "Epoch 50/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4398\n",
      "Epoch 51/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4330\n",
      "Epoch 52/100\n",
      "41347/41347 [==============================] - 53s 1ms/step - loss: 1.4309\n",
      "Epoch 53/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4239\n",
      "Epoch 54/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4162\n",
      "Epoch 55/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4130\n",
      "Epoch 56/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4060\n",
      "Epoch 57/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.4011\n",
      "Epoch 58/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3964\n",
      "Epoch 59/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3904\n",
      "Epoch 60/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3886\n",
      "Epoch 61/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3813\n",
      "Epoch 62/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3762\n",
      "Epoch 63/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3708\n",
      "Epoch 64/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3681\n",
      "Epoch 65/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3657\n",
      "Epoch 66/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3624\n",
      "Epoch 67/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3587\n",
      "Epoch 68/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3480\n",
      "Epoch 69/100\n",
      "41347/41347 [==============================] - 53s 1ms/step - loss: 1.3456\n",
      "Epoch 70/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3427\n",
      "Epoch 71/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3414\n",
      "Epoch 72/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3376\n",
      "Epoch 73/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3325\n",
      "Epoch 74/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3313\n",
      "Epoch 75/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3241\n",
      "Epoch 76/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3202\n",
      "Epoch 77/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3208\n",
      "Epoch 78/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3150\n",
      "Epoch 79/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3139\n",
      "Epoch 80/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3117\n",
      "Epoch 81/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3065\n",
      "Epoch 82/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3055\n",
      "Epoch 83/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3023\n",
      "Epoch 84/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.3005\n",
      "Epoch 85/100\n",
      "41347/41347 [==============================] - 53s 1ms/step - loss: 1.2953\n",
      "Epoch 86/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2943\n",
      "Epoch 87/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2903\n",
      "Epoch 88/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2873\n",
      "Epoch 89/100\n",
      "41347/41347 [==============================] - 53s 1ms/step - loss: 1.2842\n",
      "Epoch 90/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2831\n",
      "Epoch 91/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2789\n",
      "Epoch 92/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2781\n",
      "Epoch 93/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2728\n",
      "Epoch 94/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2699\n",
      "Epoch 95/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2689\n",
      "Epoch 96/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2659\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2613\n",
      "Epoch 98/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2596\n",
      "Epoch 99/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2597\n",
      "Epoch 100/100\n",
      "41347/41347 [==============================] - 54s 1ms/step - loss: 1.2596\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.abspath('')\n",
    "\n",
    "transformerModelPath = os.path.join(dirname, 'models/tr_reviews_{}_{}_{}_{}_{}.h5'.format(\n",
    "    EPOCHS, \n",
    "    SENTENCES_MAX_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM\n",
    "))\n",
    "\n",
    "# Build the model\n",
    "model = get_model(\n",
    "    token_num=len(word2idx),\n",
    "    embed_dim=EMBEDDING_DIM,\n",
    "    encoder_num=ENCODERS,\n",
    "    decoder_num=DECODERS,\n",
    "    head_num=HEADS_ATTENTION,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    attention_activation=ACTIVATION_FUNCTION,\n",
    "    feed_forward_activation=ACTIVATION_FUNCTION,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    embed_weights=embeddingMatrix\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer= keras.optimizers.Adam(),\n",
    "    loss= keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics={},\n",
    "    # Note: There is a bug in keras versions 2.2.3 and 2.2.4 which causes \"Incompatible shapes\" error, if any type of accuracy metric is used along with sparse_categorical_crossentropy. Use keras<=2.2.2 to use get validation accuracy.\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "if not os.path.exists(transformerModelPath):\n",
    "\n",
    "    encoderInputData, decoderInputData, decoderTargetData = generate_data(\n",
    "            word_2_idx=word2idx,\n",
    "            num_samples=numSamples,\n",
    "            max_length=SENTENCES_MAX_LENGTH, \n",
    "            vocab_length=vocabLength\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "            [encoderInputData, decoderInputData],\n",
    "            decoderTargetData,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS\n",
    "            )\n",
    "\n",
    "    model.save_weights(transformerModelPath) \n",
    "\n",
    "else : \n",
    "    print('Model already trained')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate text\n",
    "To conclude, here the prediction script, which will use the decode function from the open source library to predict the next word again and again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from: I would come with someone else\n",
      "Generated:  <START> the hotel and the location was mush its rooms and the location was much <END>\n",
      "Generating from: I only stayed for\n",
      "Generated:  <START> the bed the bed was the hotel the rate i would peeling staff were very on <END>\n",
      "Generating from: The breakfast was terrible\n",
      "Generated:  <START> and the staff were friendly and helpful <END>\n",
      "Generating from: A lovely breakfast\n",
      "Generated:  <START> and the staff were very helpful and friendly <END>\n",
      "Generating from: The breakfast\n",
      "Generated:  <START> was very good and the staff were very helpful and fresh <END>\n",
      "Generating from: Good location and the room\n",
      "Generated:  <START> was very good staff very helpful breakfast good choice <END>\n",
      "Generating from: Very kind staff\n",
      "Generated:  <START> and comfortable bed <END>\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.abspath('')\n",
    "\n",
    "transformerModelPath = os.path.join(dirname, 'models/tr_reviews_{}_{}_{}_{}_{}.h5'.format(\n",
    "    EPOCHS, \n",
    "    SENTENCES_MAX_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM)\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = get_model(\n",
    "    token_num=len(word2idx),\n",
    "    embed_dim=EMBEDDING_DIM,\n",
    "    encoder_num=ENCODERS,\n",
    "    decoder_num=DECODERS,\n",
    "    head_num=HEADS_ATTENTION,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    attention_activation=ACTIVATION_FUNCTION,\n",
    "    feed_forward_activation=ACTIVATION_FUNCTION,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    embed_weights=embeddingMatrix,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer= keras.optimizers.Adam(),\n",
    "    loss= keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics={},\n",
    "    # Note: There is a bug in keras versions 2.2.3 and 2.2.4 which causes \"Incompatible shapes\" error, if any type of accuracy metric is used along with sparse_categorical_crossentropy. Use keras<=2.2.2 to use get validation accuracy.\n",
    ")\n",
    "\n",
    "model.load_weights(transformerModelPath)\n",
    "\n",
    "sentences = [\n",
    "    'I would come with someone else',\n",
    "    'I only stayed for',\n",
    "    'The breakfast was terrible', \n",
    "    'A lovely breakfast',\n",
    "    'The breakfast',\n",
    "    'Good location and the room',\n",
    "    'Very kind staff'\n",
    "]\n",
    "\n",
    "decoded_sentences = []\n",
    "    \n",
    "for s in sentences:\n",
    "\n",
    "    print('Generating from: {}'.format(s))\n",
    "    encoderTokens = []\n",
    "    s = clean(s)\n",
    "    encoderwords = s.split(' ')\n",
    "    \n",
    "    b=True\n",
    "    while b:\n",
    "        if('' in encoderwords): \n",
    "            encoderwords.remove('')\n",
    "        else: b = False\n",
    "    \n",
    "    for w in encoderwords:\n",
    "        encoderTokens.append(word2idx[w])\n",
    "    encoderTokens = [word2idx['<START>']] + encoderTokens + [word2idx['<END>']]\n",
    "    encoderInputData = np.zeros((1, SENTENCES_MAX_LENGTH + 2), dtype='int64')\n",
    "\n",
    "    decoded = decode(\n",
    "    model,\n",
    "    encoderTokens,\n",
    "    start_token=word2idx['<START>'],\n",
    "    end_token=word2idx['<END>'],\n",
    "    pad_token=word2idx['<PAD>'],\n",
    "    max_len=SENTENCES_MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "    decodedPhrase = ''\n",
    "    for x in decoded:\n",
    "        decodedPhrase = decodedPhrase + ' ' + idx2word[x]\n",
    "\n",
    "    decoded_sentences.append(decodedPhrase)\n",
    "    print('Generated: {}'.format(decodedPhrase))\n",
    "\n",
    "resultsModelPath = os.path.join(dirname, 'output_data/out_reviews_{}_{}_{}_{}_{}.csv'.format(\n",
    "    EPOCHS, \n",
    "    SENTENCES_MAX_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM)\n",
    ")\n",
    "\n",
    "dict ={\n",
    "    'phrase' : sentences,\n",
    "    'generated' : decoded_sentences\n",
    "}\n",
    "sentiment_df = pd.DataFrame.from_dict(dict)\n",
    "sentiment_df.to_csv(resultsModelPath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

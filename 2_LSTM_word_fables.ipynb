{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import dependencies \n",
    "Tensorflow background session is launched to define GPU settings and eager excecution is enabled:\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/guide/eager\">Eager execution details</a>\n",
    "\n",
    "\n",
    "In this first step we also define all global variables that will help managing redundancy:\n",
    "\n",
    "- __*SEQUENCES_LENGTH*__: length (n. of chars) of the chuncks in which the entire text will be divided in during preprocess.\n",
    "- __*NUM_GENERATE*__: numbers of characters to be generated.\n",
    "- __*EPOCHS*__: number of epohcs in which the training is divided.\n",
    "- __*BATCH_SIZE*__: number of samples after which update the wieghts.\n",
    "- __*EMBEDDING_DIM*__: number of neurons in the Embeddings layer.\n",
    "- __*RNN_DIM*__: number of LSTM units in the networ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(session)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "SEQUENCES_LENGTH = 10\n",
    "NUM_GENERATE = 100\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "EMBEDDING_DIM = 128\n",
    "RNN_DIM = 1024 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Aesop fables data\n",
    "The chosen dataset is a JSON file containing 147 Aesop Fables divided in sentences.\n",
    "For the availabilty, I need to to thanks this funny and interesting project on Aesop Fables which explore the connections between them using machine learning: <a href=\"https://github.com/itayniv/aesop-fables-stories\">GitHub repository</a>\n",
    "\n",
    "Here an example of how it is structured:\n",
    "```json\n",
    "{\n",
    "  \"stories\":[\n",
    "    {\n",
    "      \"number\": \"01\",\n",
    "      \"title\": \"THE WOLF AND THE KID\",\n",
    "      \"story\": [\n",
    "        \"There was once a little Kid whose growing horns made him think he was a grown-up Billy Goat and able to take care of himself.\",\n",
    "        \"So one evening when the flock started home from the pasture and his mother called, the Kid paid no heed and kept right on nibbling the tender grass.\",\n",
    "        \"A little later when he lifted his head, the flock was gone.\",\n",
    "        \"He was all alone.\",\n",
    "        \"The sun was sinking.\",\n",
    "        \"Long shadows came creeping over the ground.\",\n",
    "        \"A chilly little wind came creeping with them making scary noises in the grass.\",\n",
    "        \"The Kid shivered as he thought of the terrible Wolf.\",\n",
    "        \"Then he started wildly over the field, bleating for his mother.\",\n",
    "        \"But not half-way, near a clump of trees, there was the Wolf!\",\n",
    "        \"The Kid knew there was little hope for him.\",\n",
    "        \"Please, Mr. Wolf, he said trembling, I know you are going to eat me.\",\n",
    "        \"But first please pipe me a tune, for I want to dance and be merry as long as I can.\",\n",
    "        \"The Wolf liked the idea of a little music before eating, so he struck up a merry tune and the Kid leaped and frisked gaily.\",\n",
    "        \"Meanwhile, the flock was moving slowly homeward.\",\n",
    "        \"In the still evening air the Wolf's piping carried far.\",\n",
    "        \"The Shepherd Dogs pricked up their ears.\",\n",
    "        \"They recognized the song the Wolf sings before a feast, and in a moment they were racing back to the pasture.\",\n",
    "        \"The Wolf's song ended suddenly, and as he ran, with the Dogs at his heels, he called himself a fool for turning piper to please a Kid, when he should have stuck to his butcher's trade.\"\n",
    "      ],\n",
    "      \"moral\": \"Do not let anything turn you from your purpose.\",\n",
    "      \"characters\": []\n",
    "    }, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 fables imported.\n",
      "147 plots cleaned.\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    '''\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"ain't\", \"am not\")\n",
    "    text = text.replace(\"aren't\", \"are not\")\n",
    "    text = text.replace(\"can't\", \"cannot\")\n",
    "    text = text.replace(\"can't've\", \"cannot have\")\n",
    "    text = text.replace(\"'cause\", \"because\")\n",
    "    text = text.replace(\"could've\", \"could have\")\n",
    "    text = text.replace(\"couldn't\", \"could not\")\n",
    "    text = text.replace(\"couldn't've\", \"could not have\")\n",
    "    text = text.replace(\"should've\", \"should have\")\n",
    "    text = text.replace(\"should't\", \"should not\")\n",
    "    text = text.replace(\"should't've\", \"should not have\")\n",
    "    text = text.replace(\"would've\", \"would have\")\n",
    "    text = text.replace(\"would't\", \"would not\")\n",
    "    text = text.replace(\"would't've\", \"would not have\")\n",
    "    text = text.replace(\"didn't\", \"did not\")\n",
    "    text = text.replace(\"doesn't\", \"does not\")\n",
    "    text = text.replace(\"don't\", \"do not\")\n",
    "    text = text.replace(\"hadn't\", \"had not\")\n",
    "    text = text.replace(\"hadn't've\", \"had not have\")\n",
    "    text = text.replace(\"hasn't\", \"has not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"he'd\", \"he would\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"he'd've\", \"he would have\")\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    text = text.replace(\"'t\", \"\")\n",
    "    text = text.replace(\"'ve\", \"\")\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\"!\", \" ! \")\n",
    "    text = text.replace(\"?\", \" ? \")\n",
    "    text = text.replace(\";\", \" ; \")\n",
    "    text = text.replace(\":\", \" : \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = text.replace(\"´\", \"\")\n",
    "    text = text.replace(\"‘\", \"\")\n",
    "    text = text.replace(\"’\", \"\")\n",
    "    text = text.replace(\"“\", \"\")\n",
    "    text = text.replace(\"”\", \"\")\n",
    "    text = text.replace(\"\\'\", \"\")\n",
    "    text = text.replace(\"\\\"\", \"\")\n",
    "    text = text.replace(\"-\", \"\")\n",
    "    text = text.replace(\"–\", \"\")\n",
    "    text = text.replace(\"—\", \"\")\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\",\"\")\n",
    "    text = text.replace(\"{\",\"\")\n",
    "    text = text.replace(\"}\", \"\")\n",
    "    text = text.replace(\"/\", \"\")\n",
    "    text = text.replace(\"|\", \"\")\n",
    "    text = text.replace(\"(\", \"\")\n",
    "    text = text.replace(\")\", \"\")\n",
    "    text = text.replace(\"$\", \"\")\n",
    "    text = text.replace(\"+\", \"\")\n",
    "    text = text.replace(\"*\", \"\")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    return text\n",
    "\n",
    "try:\n",
    "    \n",
    "    fables = []\n",
    "    fablesText = ''\n",
    "    dirname = os.path.abspath('')\n",
    "    filepath = os.path.join(dirname, 'input_data/aesopFables.json')\n",
    "\n",
    "    with open(filepath) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "        for p in data['stories']:\n",
    "            fables.append(' '.join(p['story']))\n",
    "            \n",
    "    print('{} fables imported.'.format(len(fables)))\n",
    "    \n",
    "    cleanedFables = []\n",
    "    for f in fables:\n",
    "        cleaned = clean(f)\n",
    "        cleanedFables.append(cleaned)\n",
    "        fablesText += ' ' + cleaned + '\\n'\n",
    "    \n",
    "    print('{} plots cleaned.'.format(len(cleanedFables)))\n",
    "    \n",
    "except IOError:\n",
    "    \n",
    "    sys.exit('Cannot find data!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to investigate on fables max length to better decided preprocess hyperparamateres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLen = 0\n",
    "for f in cleanedFables:\n",
    "    l = len(f.split(' '))\n",
    "    if l > maxLen: maxLen = l\n",
    "\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Vocabulary\n",
    "The vocabulary is saved as: \n",
    "- a __numpy array__ to map each encoding to the right word\n",
    "- a __dictionary__ to map each word to its encoding number \n",
    "\n",
    "We also create a __textAsInt__ variable that contains all fables text encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 3062\n"
     ]
    }
   ],
   "source": [
    "# CREATE VOCABULARY OF WORDS\n",
    "idx2word = []\n",
    "word2idx = {'<PAD>' : 0, '<START>' : 1 , '<END>': 2}\n",
    "wordSequence = []\n",
    "for fable in cleanedFables:\n",
    "    words = fable.split(' ')\n",
    "    wordSequence.extend(words)\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "for word in idx2word:\n",
    "    word2idx[word] = len(word2idx)\n",
    "\n",
    "idx2word = list(word2idx.keys())\n",
    "textAsInt = np.array([word2idx[w] for w in wordSequence])\n",
    "vocab_size = len(idx2word)\n",
    "print('Vocabulary Size: {}'.format(vocab_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess text\n",
    "\n",
    "Given a word, or a sequence of words, what is the most probable next word? <br/>\n",
    "This is the task we're training the model to perform, the input to the model will be a sequence of words, and we train the model to predict the following word at each time step. \n",
    "\n",
    "We're going to divide the text into sequences of words, each input sequence will contain __SEQUENCES_LENGTH__ number of words from the text. For each input sequence, the corresponding targets contain the same length of text, except shifted one word to the right.\n",
    "\n",
    "For example, say SEQUENCES_LENGTH is 4 and our text is \"Hello my name is Dario\". \n",
    "- Input: \"Hello my name is \"\n",
    "- Target: \"my name is Dario\".\n",
    "\n",
    "To do this first use the tf.data.Dataset.from_tensor_slices function to convert the text vector into a stream of words indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples per Epoch: 3019\n",
      "Steps per Epoch: 377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((8, 10), (8, 10)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    inputText = chunk[:-1]\n",
    "    targetText = chunk[1:]\n",
    "    return inputText, targetText\n",
    "\n",
    "# Create training examples and targets\n",
    "examplesPerEpoch = len(fablesText.split(' ')) // SEQUENCES_LENGTH\n",
    "stepsPerEpoch = examplesPerEpoch // BATCH_SIZE\n",
    "print('Examples per Epoch: {}'.format(examplesPerEpoch))\n",
    "print('Steps per Epoch: {}'.format(stepsPerEpoch))\n",
    "\n",
    "wordDataset = tf.data.Dataset.from_tensor_slices(textAsInt)\n",
    "sequences = wordDataset.batch(SEQUENCES_LENGTH+1, drop_remainder=True)\n",
    "dataset = sequences.map(split_input_target)\n",
    "dataset = dataset.shuffle(10000).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract embeddings matrix\n",
    "Now that we're working with words and not with characters, we can load pre-trained embeddings.\n",
    "It is a good practice to use them and in this case we calculated them with Google's Word2Vec model on the famous text8 dataset.\n",
    "- *More details on __train_embeddings.ipyn__ notebook* (To be executed if the .bin file do not exists)\n",
    "\n",
    "The embeddings are simply 128 (or whatever is the dimensionality during training) weigths from a single neuron in the input layer to the 128 neurons in the hidden layer trained to understand which words compared in the same context for a given text.\n",
    "\n",
    "So we simply extract these weights for every single word in our vocabulary and build a matrix with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 words without pre-trained embedding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Recreating embeddings index based on Tokenizer vocabulary\n",
    "word2vecModel = gensim.models.Word2Vec.load('embeddings/text8_word2vec_skipgram_128.bin')\n",
    "word2vec_vocabulary = word2vecModel.wv.vocab\n",
    "embeddingIndex = dict()\n",
    "counter = 0\n",
    "for i, word in enumerate(idx2word):\n",
    "    if word in word2vec_vocabulary :\n",
    "        embeddingIndex[word] = word2vecModel[word]\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "print(\"{} words without pre-trained embedding!\".format(counter))\n",
    "    \n",
    "# Prepare embeddings matrix\n",
    "embeddingMatrix = np.random.random((len(word2idx), EMBEDDING_DIM))\n",
    "for i, word in enumerate(idx2word):\n",
    "    embeddingVector = embeddingIndex.get(word)\n",
    "    if embeddingVector is not None:\n",
    "        embeddingMatrix[i] = embeddingVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Or it is possible to use random weights_\n",
    "Do not execute this cell to use pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMatrix = np.random.random((len(word2idx), EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build the model\n",
    "The model will be a simple Neural Network composed by:\n",
    "- Embeddings layer \n",
    "- Recurrent Layer (Long Short Memory Networks)\n",
    "- Dense layer with vocabulary size dimensionality\n",
    "\n",
    "It is also important to notice:\n",
    "- _tf.keras.layers.Embedding( ..., weights=[embeddingMatrix]_)\n",
    "\n",
    "Added with respect to the previous char-generated notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(8, 10, 3062) # (batch_size, sequence_length, vocab_size)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (8, None, 128)            391936    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm (CuDNNLSTM)       (8, None, 1024)           4726784   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (8, None, 3062)           3138550   \n",
      "=================================================================\n",
      "Total params: 8,257,270\n",
      "Trainable params: 8,257,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = tf.keras.layers.CuDNNLSTM \n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None],\n",
    "                                  weights=[embeddingMatrix]),\n",
    "        rnn(rnn_units,\n",
    "            return_sequences=True,\n",
    "            recurrent_initializer='glorot_uniform',\n",
    "            stateful=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "trainModel = build_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embedding_dim=EMBEDDING_DIM,\n",
    "  rnn_units=RNN_DIM,\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = trainModel(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "trainModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the model\n",
    "We train the model and save its weigths in .h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "377/377 [==============================] - 5s 12ms/step - loss: 5.3785\n",
      "Epoch 2/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 4.7403\n",
      "Epoch 3/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 4.3970\n",
      "Epoch 4/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 4.0775\n",
      "Epoch 5/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 3.7542\n",
      "Epoch 6/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 3.3803\n",
      "Epoch 7/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 2.9912\n",
      "Epoch 8/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 2.6199\n",
      "Epoch 9/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 2.3126\n",
      "Epoch 10/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 2.0565\n",
      "Epoch 11/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.8017\n",
      "Epoch 12/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.6499\n",
      "Epoch 13/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.5286\n",
      "Epoch 14/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.4156\n",
      "Epoch 15/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.3164\n",
      "Epoch 16/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.2429\n",
      "Epoch 17/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.1664\n",
      "Epoch 18/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.1244\n",
      "Epoch 19/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.0543\n",
      "Epoch 20/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 1.0174\n",
      "Epoch 21/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.9621\n",
      "Epoch 22/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.9363\n",
      "Epoch 23/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.8937\n",
      "Epoch 24/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.8901\n",
      "Epoch 25/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.8540\n",
      "Epoch 26/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.8347\n",
      "Epoch 27/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.8107\n",
      "Epoch 28/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.8046\n",
      "Epoch 29/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.7805\n",
      "Epoch 30/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.7811\n",
      "Epoch 31/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.7412\n",
      "Epoch 32/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.7264\n",
      "Epoch 33/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.7168\n",
      "Epoch 34/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.7132\n",
      "Epoch 35/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.7002\n",
      "Epoch 36/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6942\n",
      "Epoch 37/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6741\n",
      "Epoch 38/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6712\n",
      "Epoch 39/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6759\n",
      "Epoch 40/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6664\n",
      "Epoch 41/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6516\n",
      "Epoch 42/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6421\n",
      "Epoch 43/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6352\n",
      "Epoch 44/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6230\n",
      "Epoch 45/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6284\n",
      "Epoch 46/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6072\n",
      "Epoch 47/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6086\n",
      "Epoch 48/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6056\n",
      "Epoch 49/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6063\n",
      "Epoch 50/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.6094\n",
      "Epoch 51/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5968\n",
      "Epoch 52/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5922\n",
      "Epoch 53/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5733\n",
      "Epoch 54/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5911\n",
      "Epoch 55/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5844\n",
      "Epoch 56/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5789\n",
      "Epoch 57/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5726\n",
      "Epoch 58/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5802\n",
      "Epoch 59/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5580\n",
      "Epoch 60/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5657\n",
      "Epoch 61/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5529\n",
      "Epoch 62/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5557\n",
      "Epoch 63/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5418\n",
      "Epoch 64/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5476\n",
      "Epoch 65/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5510\n",
      "Epoch 66/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5466\n",
      "Epoch 67/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5467\n",
      "Epoch 68/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5422\n",
      "Epoch 69/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5413\n",
      "Epoch 70/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5312\n",
      "Epoch 71/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5358\n",
      "Epoch 72/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5337\n",
      "Epoch 73/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5376\n",
      "Epoch 74/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5287\n",
      "Epoch 75/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5250\n",
      "Epoch 76/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5265\n",
      "Epoch 77/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5308\n",
      "Epoch 78/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5135\n",
      "Epoch 79/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5165\n",
      "Epoch 80/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5258\n",
      "Epoch 81/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5219\n",
      "Epoch 82/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5163\n",
      "Epoch 83/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5138\n",
      "Epoch 84/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5112\n",
      "Epoch 85/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5174\n",
      "Epoch 86/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5082\n",
      "Epoch 87/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5103\n",
      "Epoch 88/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5105\n",
      "Epoch 89/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5083\n",
      "Epoch 90/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5017\n",
      "Epoch 91/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5013\n",
      "Epoch 92/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.4983\n",
      "Epoch 93/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5073\n",
      "Epoch 94/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5060\n",
      "Epoch 95/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5000\n",
      "Epoch 96/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5047\n",
      "Epoch 97/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5005\n",
      "Epoch 98/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.4961\n",
      "Epoch 99/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5024\n",
      "Epoch 100/100\n",
      "377/377 [==============================] - 4s 11ms/step - loss: 0.5039\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "trainModel.compile(\n",
    "      optimizer = tf.train.AdamOptimizer(),\n",
    "      loss = loss)\n",
    "\n",
    "trainModel.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=stepsPerEpoch)\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "weightsPath = os.path.join(dirname, 'models/LSTM_words_fables_{}_{}_{}_{}_{}_.h5'.format(\n",
    "    EPOCHS, \n",
    "    SEQUENCES_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    RNN_DIM)\n",
    ")\n",
    "trainModel.save_weights(weightsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generation model\n",
    "The generation model is the same used in training but with a __BATH_SIZE__ equal to 1 so that the model can digest one sample at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 128)            391936    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (1, None, 1024)           4726784   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 3062)           3138550   \n",
      "=================================================================\n",
      "Total params: 8,257,270\n",
      "Trainable params: 8,257,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = tf.keras.layers.CuDNNLSTM\n",
    "\n",
    "genModel = build_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embedding_dim=EMBEDDING_DIM,\n",
    "  rnn_units=RNN_DIM,\n",
    "  batch_size=1)\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "weightsPath = os.path.join(dirname, 'models/LSTM_words_fables_{}_{}_{}_{}_{}_.h5'.format(\n",
    "    EPOCHS, \n",
    "    SEQUENCES_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    RNN_DIM)\n",
    ")\n",
    "genModel.load_weights(weightsPath)\n",
    "genModel.build(tf.TensorShape([1, None]))\n",
    "genModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate text\n",
    "In order to generate a sentence with a fixed dimensionality, the following generation loop is implemented:\n",
    "\n",
    "- It Chooses a start string, initializes the RNN state and sets the number of words to generate.\n",
    "- It gets the prediction distribution of the next word using the start string and the RNN state.\n",
    "- It uses a multinomial distribution to calculate the index of the predicted word and then it uses this predicted word as our next input to the model.\n",
    "- The RNN state returned by the model is fed back into the model so that it now has more context, instead than only one word. After predicting the next word, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was once a little Bear every not see what good friends we shall become .  the waves washed it up on shore .  but his plans were very much changed when he met a lion and furiously began to tear it with their teeth .  and when they returned next day to look for visitors .  and after he had been walking .  wishing also to rest in a wolf and began to his life ,  and the goats out to feed ,  the wild goats scampered the animals respectfully made way for him ,  an ass\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, word_2_idx, idx_2_word):\n",
    "    '''\n",
    "    '''\n",
    "    # Evaluation step (generating text using the learned weights)\n",
    "    # Number of characters to generate\n",
    "    numGenerate = NUM_GENERATE\n",
    "    # Converting our start string to numbers (vectorizing) \n",
    "    s = clean(start_string)\n",
    "    inputEval = [word_2_idx[w] for w in s.split(' ')]\n",
    "    inputEval = tf.expand_dims(inputEval, 0)\n",
    "    # Empty string to store our results\n",
    "    textGenerated = []\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(numGenerate):\n",
    "        predictions = model(inputEval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a multinomial distribution to predict the word returned by the trainModel\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "        # We pass the predicted word as the next input to the trainModel\n",
    "        # along with the previous hidden state\n",
    "        inputEval = tf.expand_dims([predicted_id], 0)\n",
    "        textGenerated.append(idx_2_word[predicted_id])\n",
    "\n",
    "    return (start_string + ' ' + ' '.join(textGenerated))\n",
    "\n",
    "\n",
    "generated = generate_text(\n",
    "        model=genModel, \n",
    "        start_string=\"There was once a little Bear\", \n",
    "        word_2_idx=word2idx, \n",
    "        idx_2_word=idx2word\n",
    "    )\n",
    "\n",
    "print(generated)\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

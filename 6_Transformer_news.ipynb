{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import dependencies \n",
    "Importing needed dependencies.\n",
    "In this first step we also define all global variables that will help managing redundancy:\n",
    "- __*PREPROCESS*__: preprocessing type (Continous or splitted on dots)\n",
    "- __*EPOCHS*__: number of epochs in which the training is divided.\n",
    "- __*SENTENCES_MAX_LENGTH*__: Maximum length of the variable dimension phrases..\n",
    "- __*BATCH_SIZE*__: number of samples after which update the weights.\n",
    "- __*EMBEDDING_DIM*__: number of neurons in the Embeddings layer.\n",
    "- __*HIDDEN_DIM*__: number of LSTM units in the network.\n",
    "- __*ENCODERS*__: number of encoders in the architecture.\n",
    "- __*DECODERS*__: number of decoders in the architecture.\n",
    "- __*DROPOUT_RATE*__: Dropout value.\n",
    "- __*HEADS_ATTENTION*__: number of words considered by the self-attention mechanism.\n",
    "- __*ACTIVATION_FUNCTION*__: Used by the feedforward layers in the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.utils import shuffle\n",
    "from keras_transformer import get_model, decode\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.models import load_model\n",
    "\n",
    "EPOCHS = 100\n",
    "SENTENCES_MAX_LENGTH = 65\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 1024\n",
    "ENCODERS = 1\n",
    "DECODERS = 1\n",
    "DROPOUT_RATE = 0.1\n",
    "HEADS_ATTENTION = 8\n",
    "ACTIVATION_FUNCTION = 'relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import international news\n",
    "The data available on Kaggle was prepared in Jan 2019, so the data is very new and has got a lot of technological updates so while preprocessing please take care of all the new terms.\n",
    "\n",
    "To get more information click on <a href=\"https://www.kaggle.com/kevintoms/news-data\">link to the Kaggle website</a> .\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940 news imported and cleaned.\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    '''\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"ain't\", \"am not\")\n",
    "    text = text.replace(\"aren't\", \"are not\")\n",
    "    text = text.replace(\"can't\", \"cannot\")\n",
    "    text = text.replace(\"can't've\", \"cannot have\")\n",
    "    text = text.replace(\"'cause\", \"because\")\n",
    "    text = text.replace(\"could've\", \"could have\")\n",
    "    text = text.replace(\"couldn't\", \"could not\")\n",
    "    text = text.replace(\"couldn't've\", \"could not have\")\n",
    "    text = text.replace(\"should've\", \"should have\")\n",
    "    text = text.replace(\"should't\", \"should not\")\n",
    "    text = text.replace(\"should't've\", \"should not have\")\n",
    "    text = text.replace(\"would've\", \"would have\")\n",
    "    text = text.replace(\"would't\", \"would not\")\n",
    "    text = text.replace(\"would't've\", \"would not have\")\n",
    "    text = text.replace(\"didn't\", \"did not\")\n",
    "    text = text.replace(\"doesn't\", \"does not\")\n",
    "    text = text.replace(\"don't\", \"do not\")\n",
    "    text = text.replace(\"hadn't\", \"had not\")\n",
    "    text = text.replace(\"hadn't've\", \"had not have\")\n",
    "    text = text.replace(\"hasn't\", \"has not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"he'd\", \"he would\")\n",
    "    text = text.replace(\"haven't\", \"have not\")\n",
    "    text = text.replace(\"he'd've\", \"he would have\")\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    text = text.replace(\"'t\", \"\")\n",
    "    text = text.replace(\"'ve\", \"\")\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\"!\", \" ! \")\n",
    "    text = text.replace(\"?\", \" ? \")\n",
    "    text = text.replace(\";\", \" ; \")\n",
    "    text = text.replace(\":\", \" : \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = text.replace(\"´\", \"\")\n",
    "    text = text.replace(\"‘\", \"\")\n",
    "    text = text.replace(\"’\", \"\")\n",
    "    text = text.replace(\"“\", \"\")\n",
    "    text = text.replace(\"”\", \"\")\n",
    "    text = text.replace(\"\\'\", \"\")\n",
    "    text = text.replace(\"\\\"\", \"\")\n",
    "    text = text.replace(\"-\", \"\")\n",
    "    text = text.replace(\"–\", \"\")\n",
    "    text = text.replace(\"—\", \"\")\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\",\"\")\n",
    "    text = text.replace(\"{\",\"\")\n",
    "    text = text.replace(\"}\", \"\")\n",
    "    text = text.replace(\"/\", \"\")\n",
    "    text = text.replace(\"|\", \"\")\n",
    "    text = text.replace(\"(\", \"\")\n",
    "    text = text.replace(\")\", \"\")\n",
    "    text = text.replace(\"$\", \"\")\n",
    "    text = text.replace(\"+\", \"\")\n",
    "    text = text.replace(\"*\", \"\")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    return text\n",
    "\n",
    "try:\n",
    "    dirname = os.path.abspath('')\n",
    "    filepath = os.path.join(dirname, 'input_data/international_news.csv')\n",
    "    dataframe = pd.read_csv(filepath, sep=',')\n",
    "    newsList = dataframe['content']\n",
    "\n",
    "    trainNewsList = []\n",
    "    for news in newsList:\n",
    "        cleaned = clean(news)\n",
    "        words = cleaned.split(' ')\n",
    "        if len(words) < 65 : trainNewsList.append(cleaned)\n",
    "        \n",
    "    print('{} news imported and cleaned.'.format(len(trainNewsList)))\n",
    "\n",
    "except IOError:\n",
    "    sys.exit('Cannot find data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to investigate on news max length and average length to better decided preprocess hyperparamateres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 940\n",
      "Max length: 64\n",
      "Avg length: 61.87978723404255\n"
     ]
    }
   ],
   "source": [
    "sumLen = 0\n",
    "maxLen = 0\n",
    "\n",
    "for n in trainNewsList:\n",
    "    words = n.split(' ')\n",
    "    l = len(words)\n",
    "    sumLen += l\n",
    "    if l > maxLen : maxLen = l \n",
    "    \n",
    "avgLen = sumLen/len(trainNewsList)\n",
    "print('Number of reviews: {}'.format(len(trainNewsList)))\n",
    "print('Max length: {}'.format(maxLen))\n",
    "print('Avg length: {}'.format(avgLen))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Vocabulary\n",
    "The vocabulary is saved as: \n",
    "- a __numpy array__ to map each encoding to the right word\n",
    "- a __dictionary__ to map each word to its encoding number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<START>', '<END>']\n",
      "Vocabulary Size: 8805\n"
     ]
    }
   ],
   "source": [
    "# CREATE VOCABULARY OF WORDS\n",
    "idx2word = []\n",
    "word2idx = {'<PAD>' : 0, '<START>' : 1 , '<END>': 2}\n",
    "\n",
    "for news in trainNewsList:\n",
    "    words = news.split(' ')\n",
    "\n",
    "    b=True\n",
    "    while b:\n",
    "        if('' in words): \n",
    "            words.remove('')\n",
    "        else: b = False\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "for word in idx2word:\n",
    "    word2idx[word] = len(word2idx)\n",
    "\n",
    "idx2word = list(word2idx.keys())\n",
    "print(idx2word[:3])\n",
    "\n",
    "vocabLength = len(idx2word)\n",
    "print('Vocabulary Size: {}'.format(vocabLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess text\n",
    "\n",
    "The Transoformer model has an Encoder-Decoder architecture so we can train the model to generate variable dimension sequences, meaning that it will be the model itself to decide how many words have to be generated for a determined input sequence.\n",
    "However in order to achieve this result the text has to preprocessed in a way that let the model understand where a sequence starts and where it ends.\n",
    "In fact in the previous code cell we had these three tokens to the vocabulary:\n",
    "\n",
    "```python\n",
    "word2idx = {'<PAD>' : 0, '<START>' : 1 , '<END>': 2}\n",
    "```\n",
    "News are divided into sequences of words, respecting a maximum length decided a priori. Each sequence will generate as many samples as its number of words.\n",
    "\n",
    "For example, say SEQUENCES_LENGTH is 4 and our text is \"Hello my name is Dario and I love to code\". \n",
    "- Sequences: \"Hello my name is \", \"Dario and I love\", \"to code\"\n",
    "\n",
    "Then with the first sequence:\n",
    "- __EncoderInput__: \"START Hello END\" <br/>\n",
    "  __DecoderInput__: \"START my name is END\" <br/>\n",
    "  __Target__: \"my name is END\" <br/>\n",
    "  \n",
    "  \n",
    "- __EncoderInput__: \"START Hello my END\" <br/>\n",
    "  __DecoderInput__: \"START name is END\"<br/>\n",
    "  __Target__: \"name is END\"<br/>\n",
    "  \n",
    "  \n",
    "- __EncoderInput__:  \"START Hello my name END\"<br/>\n",
    "  __DecoderInput__: \"START is END\"<br/>\n",
    "  __Target__: \"is END\"<br/>\n",
    "  \n",
    "  \n",
    "- __EncoderInput__: \"START Hello my name is END\" <br/>\n",
    "  __DecoderInput__: \"START END\"<br/>\n",
    "  __Target__: \"END\"<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 52913\n",
      "StepsPerEpoch: 3307\n",
      "Creating dataset to feed Model . . . \n",
      "Dataset printed on CSV.\n"
     ]
    }
   ],
   "source": [
    "def createInputTarget(words) :\n",
    "    \n",
    "    encoder = []\n",
    "    decoder = []\n",
    "    output = []\n",
    "    \n",
    "    for i in range(1, len(words)):\n",
    "        encode_tokens, decode_tokens = words[:i], words[i:]\n",
    "        encode_tokens = ' '.join(['<START>'] + encode_tokens + ['<END>'])\n",
    "        output_tokens = ' '.join(decode_tokens + ['<END>'])\n",
    "        decode_tokens = ' '.join(['<START>'] + decode_tokens + ['<END>'])\n",
    "        encoder.append(encode_tokens)\n",
    "        decoder.append(decode_tokens)\n",
    "        output.append(output_tokens)\n",
    "        \n",
    "    return encoder, decoder, output\n",
    "\n",
    "def getWordTokens(sentence):\n",
    "    #clean tokens\n",
    "    words = sentence.split(' ')\n",
    "    words.append('.')\n",
    "    b=True\n",
    "    while b:\n",
    "        if('' in words): \n",
    "            words.remove('')\n",
    "        else: b = False\n",
    "    \n",
    "    return words\n",
    "\n",
    "def checkMaxLength(words):\n",
    "    \n",
    "    seq = []\n",
    "    \n",
    "    if len(words) > SENTENCES_MAX_LENGTH :\n",
    "        seq.append(words[:SENTENCES_MAX_LENGTH])\n",
    "        seq.append(words[SENTENCES_MAX_LENGTH:])\n",
    "        while len(seq[-1]) > SENTENCES_MAX_LENGTH:\n",
    "            tmp = seq[-1]\n",
    "            seq[-1] = tmp[:SENTENCES_MAX_LENGTH]\n",
    "            seq.append(tmp[SENTENCES_MAX_LENGTH:])\n",
    "    else : \n",
    "        seq.append(words)\n",
    "\n",
    "    return seq\n",
    "\n",
    "# EXTRACT ENCODER & DECODER INPUT SENTENCES\n",
    "inputSentences = []\n",
    "targetSentences = []\n",
    "outputSentences = []\n",
    "\n",
    "for news in trainNewsList :\n",
    "    words = news.split(' ')\n",
    "\n",
    "    b=True\n",
    "    while b:\n",
    "        if('' in words): \n",
    "            words.remove('')\n",
    "        else: b = False\n",
    "\n",
    "    sentences = [words[i:i+SENTENCES_MAX_LENGTH] for i in range(0, len(words), SENTENCES_MAX_LENGTH)]\n",
    "    for s in sentences:\n",
    "        for i in range(1, len(s)):\n",
    "            encode_tokens, decode_tokens = s[:i], s[i:]\n",
    "            encode_tokens = ' '.join(['<START>'] + encode_tokens + ['<END>'])\n",
    "            output_tokens = ' '.join(decode_tokens + ['<END>'])\n",
    "            decode_tokens = ' '.join(['<START>'] + decode_tokens + ['<END>'])\n",
    "            inputSentences.append(encode_tokens)\n",
    "            targetSentences.append(decode_tokens)\n",
    "            outputSentences.append(output_tokens)\n",
    "\n",
    "\n",
    "numSamples = len(inputSentences)\n",
    "print('Num samples: {}'.format(numSamples))\n",
    "stepsPerEpoch = numSamples//BATCH_SIZE\n",
    "print('StepsPerEpoch: {}'.format(stepsPerEpoch))\n",
    "\n",
    "# WRITE DATASET TO TXT  \n",
    "train_dataset = []\n",
    "\n",
    "print(\"Creating dataset to feed Model . . . \")\n",
    "dirname = os.path.abspath('')\n",
    "filePath = os.path.join(dirname, 'preprocessed/dataset_news_{}_{}_{}_{}_{}.csv'.format(\n",
    "EPOCHS, \n",
    "SENTENCES_MAX_LENGTH, \n",
    "BATCH_SIZE, \n",
    "EMBEDDING_DIM,\n",
    "HIDDEN_DIM))\n",
    "if os.path.exists(filePath):\n",
    "    os.remove(filePath) \n",
    "\n",
    "d= {'input_encoder' : inputSentences, 'input_decoder' :targetSentences, 'output_decoder':outputSentences }\n",
    "df = pd.DataFrame(data=d) \n",
    "df = shuffle(df)\n",
    "df.to_csv(filePath, index=False)\n",
    "\n",
    "print(\"Dataset printed on CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what is the purpose of the padding token?\n",
    "```python\n",
    "'<PAD>' : 0\n",
    "```\n",
    "\n",
    "In order to be able to feed the model we need to create inputs of the same length.\n",
    "This is way I defined a function to generate final data with paddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(word_2_idx, num_samples, max_length, vocab_length, batch_size=BATCH_SIZE):\n",
    "    '''\n",
    "    '''\n",
    "    dirname = os.path.abspath('')\n",
    "    filePath = os.path.join(dirname, 'preprocessed/dataset_news_{}_{}_{}_{}_{}.csv'.format(\n",
    "        EPOCHS, \n",
    "        SENTENCES_MAX_LENGTH, \n",
    "        BATCH_SIZE, \n",
    "        EMBEDDING_DIM,\n",
    "        HIDDEN_DIM))\n",
    "    df = pd.read_csv(filePath)\n",
    "    \n",
    "    encoderInputData = np.zeros((numSamples, max_length + 2), dtype='int')\n",
    "    decoderInputData = np.zeros((numSamples, max_length + 2), dtype='int')\n",
    "    decoderTargetData = np.zeros((numSamples, max_length + 2, 1),dtype='int')\n",
    "    \n",
    "    for i in range(0, numSamples):\n",
    "        if(i%10000 == 0):print('Generating feeding data... {}/{}'.format(i,numSamples))    \n",
    "        encoderTokens = df.iloc[[i]]['input_encoder'].values[0].split(' ')\n",
    "        decoderTokens = df.iloc[[i]]['input_decoder'].values[0].split(' ')\n",
    "        outputTokens = df.iloc[[i]]['output_decoder'].values[0].split(' ')\n",
    "\n",
    "        for t, word in enumerate(encoderTokens):\n",
    "            encoderInputData[i, t] = word_2_idx[word]\n",
    "        for t, word in enumerate(decoderTokens):\n",
    "            decoderInputData[i, t] = word_2_idx[word]\n",
    "        for t, word in enumerate(outputTokens):\n",
    "            # decoderTargetData is ahead of decoderInputData by one timestep\n",
    "            decoderTargetData[i, t, 0] = word_2_idx[word]\n",
    "\n",
    "    \n",
    "    return encoderInputData, decoderInputData, decoderTargetData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract embeddings matrix\n",
    "Loading pre-trained embeddings is a good practice to use them and in this case I calculated them with Google's Word2Vec model on the famous text8 dataset.\n",
    "- *More details on __train_embeddings.ipyn__ notebook* (To be executed if the .bin file do not exists)\n",
    "\n",
    "The embeddings are simply 128 (or whatever is the dimensionality during training) weigths from a single neuron in the input layer to the 128 neurons in the hidden layer trained to understand which words compared in the same context for a given text.\n",
    "\n",
    "So we simply extract these weights for every single word in our vocabulary and build a matrix with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 words without pre-trained embedding!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Recreating embeddings index based on Tokenizer vocabulary\n",
    "word2vecModel = gensim.models.Word2Vec.load('embeddings/news_word2vec_skipgram_128.bin')\n",
    "word2vec_vocabulary = word2vecModel.wv.vocab\n",
    "embeddingIndex = dict()\n",
    "counter = 0\n",
    "for i, word in enumerate(idx2word):\n",
    "    if word in word2vec_vocabulary :\n",
    "        embeddingIndex[word] = word2vecModel[word]\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "print(\"{} words without pre-trained embedding!\".format(counter))\n",
    "    \n",
    "# Prepare embeddings matrix\n",
    "embeddingMatrix = np.random.random((len(word2idx), EMBEDDING_DIM))\n",
    "for i, word in enumerate(idx2word):\n",
    "    embeddingVector = embeddingIndex.get(word)\n",
    "    if embeddingVector is not None:\n",
    "        embeddingMatrix[i] = embeddingVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Or it is possible to use random weights_\n",
    "Do not execute this cell to use pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMatrix = np.random.random((len(word2idx), EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the model\n",
    "To build the transformer model I use and external library available on <a href=\"https://github.com/kpot/keras-transformer\">this GitHub repository</a>.\n",
    "The the model is trained and its weight are saved in a .h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Token-Embedding (EmbeddingRet)  [(None, None, 128),  1127040     Encoder-Input[0][0]              \n",
      "                                                                 Decoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Embedding (TrigPosEmbed (None, None, 128)    0           Token-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    66048       Encoder-Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Encoder-Embedding[0][0]          \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Embedding (TrigPosEmbed (None, None, 128)    0           Token-Embedding[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 128)    256         Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 128)    66048       Decoder-Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, None, 128)    263296      Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Decoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, None, 128)    0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 128)    0           Decoder-Embedding[0][0]          \n",
      "                                                                 Decoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, None, 128)    0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadSelfAttentio (None, None, 128)    256         Decoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, None, 128)    256         Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 128)    66048       Decoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 128)    0           Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 128)    0           Decoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-MultiHeadQueryAttenti (None, None, 128)    256         Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward (FeedForw (None, None, 128)    263296      Decoder-1-MultiHeadQueryAttention\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Dropout ( (None, None, 128)    0           Decoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Add (Add) (None, None, 128)    0           Decoder-1-MultiHeadQueryAttention\n",
      "                                                                 Decoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Decoder-1-FeedForward-Norm (Lay (None, None, 128)    256         Decoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Output (EmbeddingSim)           (None, None, 8805)   8805        Decoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Token-Embedding[1][1]            \n",
      "==================================================================================================\n",
      "Total params: 1,861,861\n",
      "Trainable params: 734,821\n",
      "Non-trainable params: 1,127,040\n",
      "__________________________________________________________________________________________________\n",
      "Generating feeding data... 0/52913\n",
      "Generating feeding data... 10000/52913\n",
      "Generating feeding data... 20000/52913\n",
      "Generating feeding data... 30000/52913\n",
      "Generating feeding data... 40000/52913\n",
      "Generating feeding data... 50000/52913\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/100\n",
      "52913/52913 [==============================] - 94s 2ms/step - loss: 5.2292\n",
      "Epoch 2/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 4.3093\n",
      "Epoch 3/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 3.7051\n",
      "Epoch 4/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 3.3332\n",
      "Epoch 5/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 3.0981\n",
      "Epoch 6/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.9332\n",
      "Epoch 7/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.8097\n",
      "Epoch 8/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.7109\n",
      "Epoch 9/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.6350\n",
      "Epoch 10/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.5656\n",
      "Epoch 11/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.5092\n",
      "Epoch 12/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.4587\n",
      "Epoch 13/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.4195\n",
      "Epoch 14/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.3794\n",
      "Epoch 15/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.3433\n",
      "Epoch 16/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.3111\n",
      "Epoch 17/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.2818\n",
      "Epoch 18/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.2564\n",
      "Epoch 19/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.2330\n",
      "Epoch 20/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.2088\n",
      "Epoch 21/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.1860\n",
      "Epoch 22/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.1679\n",
      "Epoch 23/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.1483\n",
      "Epoch 24/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 2.1309\n",
      "Epoch 25/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.1144\n",
      "Epoch 26/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.1000\n",
      "Epoch 27/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.0864\n",
      "Epoch 28/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.0699\n",
      "Epoch 29/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.0562\n",
      "Epoch 30/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.0430\n",
      "Epoch 31/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.0329\n",
      "Epoch 32/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.0206\n",
      "Epoch 33/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.0097\n",
      "Epoch 34/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 2.0006\n",
      "Epoch 35/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.9867\n",
      "Epoch 36/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.9805\n",
      "Epoch 37/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.9680\n",
      "Epoch 38/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.9653\n",
      "Epoch 39/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.9533\n",
      "Epoch 40/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.9432\n",
      "Epoch 41/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.9362\n",
      "Epoch 42/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.9287\n",
      "Epoch 43/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.9206\n",
      "Epoch 44/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.9130\n",
      "Epoch 45/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.9024\n",
      "Epoch 46/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.8994\n",
      "Epoch 47/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.8922\n",
      "Epoch 48/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.8872\n",
      "Epoch 49/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8793\n",
      "Epoch 50/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8745\n",
      "Epoch 51/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.8681\n",
      "Epoch 52/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.8639\n",
      "Epoch 53/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8574\n",
      "Epoch 54/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8516\n",
      "Epoch 55/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.8464\n",
      "Epoch 56/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.8400\n",
      "Epoch 57/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.8353\n",
      "Epoch 58/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8294\n",
      "Epoch 59/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8259\n",
      "Epoch 60/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8235\n",
      "Epoch 61/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8143\n",
      "Epoch 62/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8115\n",
      "Epoch 63/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8069\n",
      "Epoch 64/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8018\n",
      "Epoch 65/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.8003\n",
      "Epoch 66/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7950\n",
      "Epoch 67/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.7920\n",
      "Epoch 68/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7850\n",
      "Epoch 69/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7822\n",
      "Epoch 70/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7776\n",
      "Epoch 71/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7757\n",
      "Epoch 72/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7736\n",
      "Epoch 73/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7696\n",
      "Epoch 74/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7652\n",
      "Epoch 75/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.7595\n",
      "Epoch 76/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7556\n",
      "Epoch 77/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7551\n",
      "Epoch 78/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7500\n",
      "Epoch 79/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.7492\n",
      "Epoch 80/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7453\n",
      "Epoch 81/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7398\n",
      "Epoch 82/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7376\n",
      "Epoch 83/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.7367\n",
      "Epoch 84/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7342\n",
      "Epoch 85/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7286\n",
      "Epoch 86/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7262\n",
      "Epoch 87/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7226\n",
      "Epoch 88/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7201\n",
      "Epoch 89/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7180\n",
      "Epoch 90/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7148\n",
      "Epoch 91/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7145\n",
      "Epoch 92/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7081\n",
      "Epoch 93/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.7083\n",
      "Epoch 94/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.7065\n",
      "Epoch 95/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.7024\n",
      "Epoch 96/100\n",
      "52913/52913 [==============================] - 91s 2ms/step - loss: 1.7006\n",
      "Epoch 97/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.6998\n",
      "Epoch 98/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.6947\n",
      "Epoch 99/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.6908\n",
      "Epoch 100/100\n",
      "52913/52913 [==============================] - 92s 2ms/step - loss: 1.6888\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.abspath('')\n",
    "\n",
    "transformerModelPath = os.path.join(dirname, 'models/tr_news_{}_{}_{}_{}_{}.h5'.format(\n",
    "    EPOCHS, \n",
    "    SENTENCES_MAX_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM)\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = get_model(\n",
    "    token_num=len(word2idx),\n",
    "    embed_dim=EMBEDDING_DIM,\n",
    "    encoder_num=ENCODERS,\n",
    "    decoder_num=DECODERS,\n",
    "    head_num=HEADS_ATTENTION,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    attention_activation=ACTIVATION_FUNCTION,\n",
    "    feed_forward_activation=ACTIVATION_FUNCTION,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    embed_weights=embeddingMatrix,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer= keras.optimizers.Adam(),\n",
    "    loss= keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics={},\n",
    "    # Note: There is a bug in keras versions 2.2.3 and 2.2.4 which causes \"Incompatible shapes\" error, if any type of accuracy metric is used along with sparse_categorical_crossentropy. Use keras<=2.2.2 to use get validation accuracy.\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "if not os.path.exists(transformerModelPath):\n",
    "\n",
    "    encoderInputData, decoderInputData, decoderTargetData = generate_data(\n",
    "            word_2_idx=word2idx,\n",
    "            num_samples=numSamples,\n",
    "            max_length=SENTENCES_MAX_LENGTH, \n",
    "            vocab_length=vocabLength\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "            [encoderInputData, decoderInputData],\n",
    "            decoderTargetData,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS\n",
    "            )\n",
    "\n",
    "    model.save_weights(transformerModelPath) \n",
    "\n",
    "else : \n",
    "    print('Model already trained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate text\n",
    "To conclude, here the prediction script, which will use the decode function from the open source library to predict the next word again and again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from: Facebook CEO said privacy is not so important\n",
      "Generated:  <START> has said that his serving a single asian cup for the next years of its acquisition for users future movement , messenger . talk to give life up a sense of health took to a quick and better said , pichai further said . <END>\n",
      "Generating from: Whatsapp users have complained that their privacy is not important for the company after\n",
      "Generated:  <START> the first list of its app . the app is and care has confirmed their profile that discovered the sound to live game , super games and great efficiently third their tied aibased air this year . <END>\n",
      "Generating from: Police arrested a man after a woman claimed he had been following her since Friday. \n",
      "Generated:  <START> a message on a christmas on thursday till scheduled to meet being committed suicide but said she died from entering and declared him . the victim mother and started an from female children . the argument sex to death . <END>\n",
      "Generating from: China developed new social network and the app is ready for release. Citizens will identify others with a smartphone camera.\n",
      "Generated:  <START> the directions of the warships of the pipe on various issues . the aimed at its aimed at look inside the eden final . the analyser hole crashed hurled and netflix new technology . <END>\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.abspath('')\n",
    "\n",
    "transformerModelPath = os.path.join(dirname, 'models/tr_news_{}_{}_{}_{}_{}.h5'.format(\n",
    "    EPOCHS, \n",
    "    SENTENCES_MAX_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM)\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = get_model(\n",
    "    token_num=len(word2idx),\n",
    "    embed_dim=EMBEDDING_DIM,\n",
    "    encoder_num=ENCODERS,\n",
    "    decoder_num=DECODERS,\n",
    "    head_num=HEADS_ATTENTION,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    attention_activation=ACTIVATION_FUNCTION,\n",
    "    feed_forward_activation=ACTIVATION_FUNCTION,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    embed_weights=embeddingMatrix,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer= keras.optimizers.Adam(),\n",
    "    loss= keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics={},\n",
    "    # Note: There is a bug in keras versions 2.2.3 and 2.2.4 which causes \"Incompatible shapes\" error, if any type of accuracy metric is used along with sparse_categorical_crossentropy. Use keras<=2.2.2 to use get validation accuracy.\n",
    ")\n",
    "\n",
    "model.load_weights(transformerModelPath)\n",
    "\n",
    "sentences = [\n",
    "    'Facebook CEO said privacy is not so important',\n",
    "    'Whatsapp users have complained that their privacy is not important for the company after', \n",
    "    'Police arrested a man after a woman claimed he had been following her since Friday. ' , \n",
    "    'China developed new social network and the app is ready for release. Citizens will identify others with a smartphone camera.',\n",
    "]\n",
    "\n",
    "decoded_sentences = []\n",
    "    \n",
    "for s in sentences:\n",
    "\n",
    "    print('Generating from: {}'.format(s))\n",
    "    encoderTokens = []\n",
    "    s = clean(s)\n",
    "    encoderwords = s.split(' ')\n",
    "    \n",
    "    b=True\n",
    "    while b:\n",
    "        if('' in encoderwords): \n",
    "            encoderwords.remove('')\n",
    "        else: b = False\n",
    "    \n",
    "    for w in encoderwords:\n",
    "        encoderTokens.append(word2idx[w])\n",
    "    encoderTokens = [word2idx['<START>']] + encoderTokens + [word2idx['<END>']]\n",
    "    encoderInputData = np.zeros((1, SENTENCES_MAX_LENGTH + 2), dtype='int64')\n",
    "\n",
    "    decoded = decode(\n",
    "    model,\n",
    "    encoderTokens,\n",
    "    start_token=word2idx['<START>'],\n",
    "    end_token=word2idx['<END>'],\n",
    "    pad_token=word2idx['<PAD>'],\n",
    "    max_len=SENTENCES_MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "    decodedPhrase = ''\n",
    "    for x in decoded:\n",
    "        decodedPhrase = decodedPhrase + ' ' + idx2word[x]\n",
    "\n",
    "    decoded_sentences.append(decodedPhrase)\n",
    "    print('Generated: {}'.format(decodedPhrase))\n",
    "\n",
    "resultsModelPath = os.path.join(dirname, 'output_data/out_fable_{}_{}_{}_{}_{}.csv'.format(\n",
    "    EPOCHS, \n",
    "    SENTENCES_MAX_LENGTH, \n",
    "    BATCH_SIZE, \n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM)\n",
    ")    \n",
    "\n",
    "dict ={\n",
    "    'phrase' : sentences,\n",
    "    'generated' : decoded_sentences\n",
    "}\n",
    "sentiment_df = pd.DataFrame.from_dict(dict)\n",
    "sentiment_df.to_csv(resultsModelPath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
